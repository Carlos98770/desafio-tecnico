# ğŸ©º API (Lacrei SaÃºde)

API REST desenvolvida com **Django REST Framework (DRF)** para o gerenciamento de **profissionais de saÃºde** e **consultas mÃ©dicas**.

O projeto Ã© totalmente containerizado com **Docker**, utiliza **PostgreSQL** como banco de dados e implementa um pipeline de **CI/CD** com **GitHub Actions** para build, teste, push para o **Docker Hub** e deploy automatizado em uma instÃ¢ncia **AWS EC2**.

---

## Tabela de ConteÃºdo

- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Arquitetura e Estrutura do Projeto](#-arquitetura-e-estrutura-do-projeto)
- [ConfiguraÃ§Ã£o do Ambiente Local](#-configuraÃ§Ã£o-do-ambiente-local)
- [DocumentaÃ§Ã£o da API (Endpoints)](#-documentaÃ§Ã£o-da-api-endpoints)
- [AutenticaÃ§Ã£o](#-autenticaÃ§Ã£o)
- [Testes Automatizados](#-testes-automatizados)
- [Pipeline de CI/CD](#-pipeline-de-cicd)
- [Deploy na AWS EC2](#-deploy-na-aws-ec2)
- [SeguranÃ§a e GitHub Secrets](#-seguranÃ§a-e-github-secrets)
- [ExplicaÃ§Ãµes sobre DecisÃµes TÃ©cnicas](#-explicaÃ§Ãµes-sobre-decisÃµes-tÃ©cnicas)
- [DecisÃµes, Dificuldades e Melhorias](#-decisÃµes-dificuldades-e-melhorias)
- [Autor](#-autor)

---

## ğŸš€ Tecnologias Utilizadas

Este projeto utiliza um stack moderno focado em escalabilidade:

-   ğŸ **Python** & **Poetry**: Gerenciamento de dependÃªncias e ambiente virtual.
-   ğŸ’» **Django** & **Django REST Framework**: Backend robusto para criaÃ§Ã£o da API.
-   ğŸ—ƒï¸ **PostgreSQL**: Banco de dados relacional.
-   ğŸ³ **Docker** & **Docker Compose**: ContainerizaÃ§Ã£o e orquestraÃ§Ã£o dos serviÃ§os.
-   â˜ï¸ **AWS EC2**: Servidor em nuvem para hospedagem da aplicaÃ§Ã£o.
-   ğŸ“¦ **Docker Hub**: Registro para armazenamento das imagens Docker.
-   ğŸ”„ **GitHub Actions**: AutomaÃ§Ã£o do pipeline de IntegraÃ§Ã£o ContÃ­nua e Deploy ContÃ­nuo (CI/CD).

---

## ğŸ“ Arquitetura e Estrutura do Projeto

A estrutura do projeto segue o padrÃ£o Django, separando a lÃ³gica da API em um app dedicado (`api`) e as configuraÃ§Ãµes do projeto em `lacrei_saude`.

```bash
    .
â”œâ”€â”€ api
â”‚Â Â  â”œâ”€â”€ admin.py
â”‚Â Â  â”œâ”€â”€ apps.py
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ migrations/
â”‚Â Â  â”œâ”€â”€ models.py
â”‚Â Â  â”œâ”€â”€ permissions.py
â”‚Â Â  â”œâ”€â”€ serializers.py
â”‚Â Â  â”œâ”€â”€ tests
â”‚Â Â  â”œâ”€â”€ urls.py
â”‚Â Â  â””â”€â”€ views.py
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ lacrei_saude
â”‚Â Â  â”œâ”€â”€ asgi.py
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ settings.py
â”‚Â Â  â”œâ”€â”€ urls.py
â”‚Â Â  â””â”€â”€ wsgi.py
â”œâ”€â”€ manage.py
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ script.sh
â””â”€â”€ .github/workflows
    â”œâ”€â”€ ci_cd.yaml



```

---

##  ConfiguraÃ§Ã£o do Ambiente Local

Para executar este projeto localmente usando Docker, siga os passos abaixo.

### PrÃ©-requisitos

-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/get-started)
-   [Docker Compose](https://docs.docker.com/compose/install/)

### InstruÃ§Ãµes para rodar o projeto

1.  **Clone o repositÃ³rio:**
    ```sh
    git clone [https://github.com/Carlos98770/desafio-tecnico](https://github.com/Carlos98770/desafio-tecnico)
    cd desafio-tecnico
    ```

2.  **Crie o arquivo de ambiente:**
    Crie o arquivo`.env` no diretorio do projeto:

    ```bash
    API_KEY=sua_api_key
    DB_HOST=db  #manter "db"
    DB_NAME=seu_nome_banco
    DB_USER=seu-user
    DB_PASSWORD=sua-senha
    DB_PORT=5432
    DEBUG=True
    ALLOWED_HOSTS=localhost
        
    DATABASE_URL=postgres://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}

    ```

3.  **Ajuste o `docker-compose.yaml` para Desenvolvimento:**
    O arquivo `docker-compose.yaml` vem configurado por padrÃ£o para **produÃ§Ã£o** (usando a imagem pronta `carlos98770/django_rest-api:latest`). Para rodar em modo de **desenvolvimento local**, vocÃª precisa alterÃ¡-lo:

    * **Comente** as linhas da seÃ§Ã£o `#producao`.
    * **Descomente** as linhas da seÃ§Ã£o `#desenvolvimento`.

    **Antes (PadrÃ£o - ProduÃ§Ã£o):**
    ```yaml
      app:
        #producao
        image: carlos98770/django_rest-api:latest
        container_name: app_app_1
        env_file:
          - .env
        depends_on:
          - db
        ports:
          - "8000:8000"  

        #desenvolvimento
        # build: .
        # volumes:
        #   - .:/app
        # env_file:
        #   - .env
        # depends_on:
        #   - db
        # ports:
        #   - "8000:8000"
    ```

    **Depois (Modo Desenvolvimento):**
    ```yaml
      app:
        #producao
        # image: carlos98770/django_rest-api:latest
        # container_name: app_app_1
        # env_file:
        #   - .env
        # depends_on:
        #   - db
        # ports:
        #   - "8000:8000"  

        #desenvolvimento
        build: .
        volumes:
          - .:/app
        env_file:
          - .env
        depends_on:
          - db
        ports:
          - "8000:8000"
    ```
    * **Por quÃª?** O modo desenvolvimento usa `build: .` (constrÃ³i a imagem localmente) e `volumes: - .:/app` (espelha seu cÃ³digo local dentro do container). Isso permite que o servidor Django reinicie automaticamente (hot-reload) sempre que vocÃª salvar uma alteraÃ§Ã£o no cÃ³digo.

4.  **Construa e suba os containers:**
    Este comando irÃ¡ construir a imagem da aplicaÃ§Ã£o (se nÃ£o existir) e iniciar os serviÃ§os `app` (Django) e `db` (PostgreSQL) em background.
    ```sh
    sudo docker-compose up -d --build
    ```
     -  **Nota:** O container da API (`app`) executa o `script.sh` na inicializaÃ§Ã£o, que jÃ¡ **aguarda o PostgreSQL**, **aplica as migraÃ§Ãµes** automaticamente (`python manage.py migrate`) e **inicia o servidor Django**. Caso o `script.sh` tenha sido editado no Windows, certifique-se de que ele esteja utilizando o formato de quebra de linha **LF (Unix)** para evitar erros de execuÃ§Ã£o no ambiente Linux do container.

5.  **(Opcional) Crie um superusuÃ¡rio:**
    Para acessar a interface de admin do Django (`/admin`).
    ```sh
    docker-compose exec app poetry run python manage.py createsuperuser
    ```

ğŸ‰ **Pronto!** A API estarÃ¡ acessÃ­vel em `http://localhost:8000/api/`.

---

## ğŸ—ºï¸ DocumentaÃ§Ã£o da API (Endpoints)

A URL base para todos os endpoints Ã© `/api/`. 

| MÃ©todo HTTP | Endpoint | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `GET` | `/profissionais/` | Lista todos os profissionais de saÃºde. |
| `POST` | `/profissionais/` | Cria um novo profissional. |
| `GET` | `/profissionais/<id>/` | ObtÃ©m detalhes de um profissional especÃ­fico. |
| `PUT` | `/profissionais/<id>/` | Atualiza (completo) um profissional especÃ­fico. |
| `PATCH` | `/profissionais/<id>/` | Atualiza (parcial) um profissional especÃ­fico. |
| `DELETE` | `/profissionais/<id>/` | Remove um profissional. |
| `GET` | `/consultas/` | Lista todas as consultas agendadas. |
| `POST` | `/consultas/` | Agenda uma nova consulta. |
| `GET` | `/consultas/<id>/` | ObtÃ©m detalhes de uma consulta especÃ­fica. |
| `DELETE` | `/consultas/<id>/` | Cancela (remove) uma consulta. |
| `GET` | `/consultas/profissional/<id>/` | Lista todas as consultas de um profissional especÃ­fico. |

---


## ğŸ”‘ AutenticaÃ§Ã£o e seguranÃ§a


A API implementa duas camadas principais de seguranÃ§a: autenticaÃ§Ã£o por API Key e controle de acesso de origem (CORS).

1 -  **API Key**. Esta implementaÃ§Ã£o utiliza uma classe de permissÃ£o customizada (`api/permissions.py`) que verifica a chave em cada requisiÃ§Ã£o.

Para se autenticar, inclua a chave no cabeÃ§alho `Authorization` da sua requisiÃ§Ã£o, prefixada com `ApiKey`.

**Exemplo de Header:**

```sh
    Authorization: Api-Key SUA_CHAVE_SECRETA_DEFINIDA_NO_ENV
```

A chave utilizada pelo servidor Ã© definida na variÃ¡vel de ambiente `API_KEY`.

2 - **CORS**:
- O projeto utiliza django-cors-headers para restringir quais domÃ­nios podem fazer requisiÃ§Ãµes Ã  API a partir de um navegador.

- Em ProduÃ§Ã£o (DEBUG=False): Apenas as origens listadas na variÃ¡vel de ambiente CORS_ORIGINS sÃ£o permitidas. Ex: CORS_ORIGINS=https://frontend.com.

- Em Desenvolvimento (DEBUG=True): Para facilitar os testes locais, origens comuns como http://localhost:5173 e http://localhost:8000 sÃ£o permitidas automaticamente

---

## ğŸ›¡ï¸ ValidaÃ§Ã£o e SanitizaÃ§Ã£o de Dados

Este projeto implementa rotinas robustas de sanitizaÃ§Ã£o e validaÃ§Ã£o nos serializers do DRF (serializers.py) para garantir a integridade e a consistÃªncia dos dados recebidos pela API.

1. SanitizaÃ§Ã£o (Limpeza de Dados): Os dados de entrada sÃ£o "limpos" antes de serem validados:

- RemoÃ§Ã£o de EspaÃ§os: Campos de texto (como social_name, adress) utilizam .strip() para remover espaÃ§os em branco no inÃ­cio e no fim.

- NormalizaÃ§Ã£o de Telefone: O phone_number passa por um re.sub() para remover todos os caracteres nÃ£o numÃ©ricos (como (, ), -, ), armazenando apenas os dÃ­gitos.

2. ValidaÃ§Ãµes (Regras de NegÃ³cio)

- ApÃ³s a limpeza, os dados sÃ£o validados para garantir que atendem Ã s regras da aplicaÃ§Ã£o:

- Campos ObrigatÃ³rios: Verifica-se se campos essenciais (como social_name, adress, professional_register) nÃ£o estÃ£o vazios apÃ³s a sanitizaÃ§Ã£o.

- Formato de Registro: O professional_register sÃ³ aceita caracteres alfanumÃ©ricos e hÃ­fen.

- Formato de Telefone: phone_number deve conter um nÃºmero mÃ­nimo de dÃ­gitos (10) apÃ³s a limpeza.

- Datas de Consultas: O campo data em ConsultasSerializer nÃ£o pode aceitar datas no passado.

- Regras de Objeto: O mÃ©todo validate() do ConsultasSerializer verifica regras cruzadas, como impedir o agendamento com profissionais considerados inativos.


## ğŸ§ª Testes Automatizados

O projeto possui uma suÃ­te de testes (localizada em `api/tests/`) que valida:
-   A lÃ³gica dos **Models** (Profissional e Consulta).
-   As operaÃ§Ãµes **CRUD** via API.
-   O funcionamento correto dos **Endpoints**, incluindo cÃ³digos de status e validaÃ§Ãµes de dados.

Para executar os testes, utilize o seguinte comando (com os containers rodando):

```sh
docker-compose exec app poetry run python manage.py test api
```

---

---

## ğŸ”„ Pipeline de CI/CD

Este projeto utiliza **GitHub Actions** para automaÃ§Ã£o de IntegraÃ§Ã£o ContÃ­nua (CI) e Deploy ContÃ­nuo (CD). O fluxo de trabalho estÃ¡ definido no arquivo `.github/workflows/ci_cd.yaml`.

O pipeline Ã© acionado automaticamente a cada `push` ou `pull request` para a branch `main` e `develop`.

### 1. IntegraÃ§Ã£o ContÃ­nua (CI)

A etapa de CI Ã© executada em **todas as atualizaÃ§Ãµes** (`push` ou `pull request`) e garante a qualidade e integridade do cÃ³digo.

1.  **Setup do Ambiente:** O job configura o Python 3.13 e instala o Poetry.
2.  **Banco de Testes:** Um container de serviÃ§o com **PostgreSQL 15** Ã© iniciado para ser usado durante os testes.
3.  **InstalaÃ§Ã£o:** As dependÃªncias do projeto sÃ£o instaladas usando `poetry install`.
4.  **Lint & FormataÃ§Ã£o:** O cÃ³digo Ã© verificado contra padrÃµes de formataÃ§Ã£o (`black`) e linting (`flake8`).
5.  **Testes Automatizados:** O pipeline aguarda o banco de dados de teste ficar pronto, aplica as migraÃ§Ãµes (`manage.py migrate`) e executa a suÃ­te de testes completa (`manage.py test api`).

### 2. Deploy ContÃ­nuo (CD)

A etapa de CD sÃ³ Ã© executada se a etapa de CI for bem-sucedida:

1.  **Build da Imagem:** A imagem Docker da aplicaÃ§Ã£o Ã© construÃ­da localmente no runner do GitHub.
2.  **Login no Docker Hub:** O pipeline se autentica no Docker Hub usando as credenciais `DOCKERHUB_USERNAME` e `DOCKERHUB_TOKEN` armazenadas nos secrets.
3.  **Push da Imagem:** A imagem recÃ©m-construÃ­da Ã© enviada para o registro do Docker Hub.
4.  **Deploy na AWS EC2:**
    * O pipeline se conecta Ã  instÃ¢ncia EC2 via SSH (usando `EC2_HOST`, `EC2_USER`, `EC2_KEY`).
    * Um script Ã© executado remotamente no servidor para:
        * Navegar atÃ© o diretÃ³rio da aplicaÃ§Ã£o (`~/app_prod`) ou (`~/app_staging`).
        * Parar os serviÃ§os atuais com `docker-compose down`.
        * Baixar a nova imagem que acabamos de enviar para o Docker Hub (`docker pull ${{ secrets.DOCKERHUB_USERNAME }}/django-api:{tag}`).
        * Iniciar os serviÃ§os novamente com a imagem atualizada (`docker-compose up -d --build`).

---

## â˜ï¸ Deploy na AWS EC2

A aplicaÃ§Ã£o Ã© hospedada em uma instÃ¢ncia **AWS EC2** (Ubuntu Server), onde coexistem dois ambientes isolados: **Staging** (para testes) e **ProduÃ§Ã£o**.

### ConfiguraÃ§Ã£o do Servidor

Para que o deploy automatizado funcione, o servidor EC2 foi configurado com os seguintes prÃ©-requisitos:

1.  **Docker** e **Docker Compose** instalados.
2.  **Portas Liberadas:** As portas necessÃ¡rias estÃ£o abertas no Security Group da AWS:
    * Porta `8000`: Para a aplicaÃ§Ã£o de **ProduÃ§Ã£o**.
    * Porta `8001`: Para a aplicaÃ§Ã£o de **Staging**.
    * Porta `5432` (DB ProduÃ§Ã£o) e `5433` (DB Staging).
3.  **Chave SSH:** A chave pÃºblica SSH do repositÃ³rio (`EC2_SSH_KEY`) estÃ¡ autorizada no arquivo `~/.ssh/authorized_keys` do usuÃ¡rio de deploy.

### Ambientes (Staging e ProduÃ§Ã£o)

Para garantir o isolamento total, os ambientes sÃ£o gerenciados em diretÃ³rios separados no servidor, cada um contendo seus prÃ³prios arquivos de configuraÃ§Ã£o:

* **ProduÃ§Ã£o:**
    * **Local:** `~/app_prod/`
    * **Arquivos:** ContÃ©m seu prÃ³prio `docker-compose.yaml` (com `container_name: ..._prod`, porta `8000`) e seu arquivo `.env` (com as credenciais de produÃ§Ã£o).

* **Staging:**
    * **Local:** `~/app_staging/`
    * **Arquivos:** ContÃ©m seu prÃ³prio `docker-compose.yaml` (com `container_name: ..._staging`, porta `8001`) e seu arquivo `.env` (com credenciais de teste/staging).
  
  Exemplo de docker-compose.yaml usado:
  ```sh
    version: "3.9"
    services:
      db:
        image: postgres:15
        container_name: postgres_db_staging
        restart: always
        environment:
          POSTGRES_DB: ${DB_NAME}
          POSTGRES_USER: ${DB_USER}
          POSTGRES_PASSWORD: ${DB_PASSWORD}
        volumes:
          - ./data/db_staging:/var/lib/postgresql/data
        ports:
          - "5433:5432" # Porta diferente para nÃ£o dar conflito com a produÃ§Ã£o
      app:
        image: carlos98770/django-api:e927c62
        container_name: app_staging
        restart: always
        env_file: .env
        depends_on:
          - db
        ports:
          - "8001:8000" # Porta diferente
    volumes:
      postgres_data:  
    ```


  

### Processo de Deploy (CI/CD)

O pipeline de CI/CD (definido em `.github/workflows/ci_cd.yml`) agora gerencia os dois ambientes baseado na estratÃ©gia de branches:

1.  **Build e Teste:** A cada `push` ou `pull request` em `main` ou `develop`, o pipeline executa os testes, lints e o build da imagem Docker.
2.  **Tagging e Push:** A imagem Ã© versionada com o hash do commit (ex: `...:a1b2c3d`) e enviada ao Docker Hub.
3.  **Deploy em Staging:**
    * **Gatilho:** Um `push` (ou merge) na branch `develop`.
    * **AÃ§Ã£o:** O pipeline se conecta via SSH, entra no diretÃ³rio `~/app_staging`, atualiza o `docker-compose.yaml` para usar a nova tag da imagem, baixa a imagem e reinicia os serviÃ§os de *staging*.
4.  **Deploy em ProduÃ§Ã£o:**
    * **Gatilho:** Um `push` (ou merge) na branch `main`.
    * **AÃ§Ã£o:** O pipeline executa o mesmo processo, mas desta vez no diretÃ³rio `~/app_prod`, atualizando a aplicaÃ§Ã£o de produÃ§Ã£o.

### Fluxo de Rollback

GraÃ§as ao deploy que utiliza tags de imagem Ãºnicas baseadas no commit, um rollback de emergÃªncia Ã© direto e seguro:

1.  **Identifique** a tag da imagem da versÃ£o estÃ¡vel anterior (ex: `...:z9y8x7w`) nos logs do Docker Hub ou do GitHub Actions.
2.  **Acesse** o servidor EC2 via SSH.
3.  **Navegue** atÃ© o diretÃ³rio do ambiente com falha (`~/app_prod` ou `~/app_staging`).
4.  **Edite** o `docker-compose.yaml` (ex: `nano docker-compose.yaml`).
5.  **Altere** a linha `image:` para apontar para a tag da versÃ£o estÃ¡vel anterior.
6.  **Execute** `docker-compose up -d`. O Docker irÃ¡ parar o container com bug e substituÃ­-lo pela versÃ£o anterior em segundos.

### ğŸŒ EndereÃ§os de Acesso

A aplicaÃ§Ã£o estÃ¡ hospedada em uma instÃ¢ncia **AWS EC2 (Ubuntu Server 22.04)** e pode ser acessada nos seguintes endereÃ§os pÃºblicos:

| Ambiente     | URL de Acesso                                            | Porta | DescriÃ§Ã£o                             |
| ------------- | -------------------------------------------------------- | ----- | ------------------------------------- |
| **ProduÃ§Ã£o** | [`http://54.163.215.33:8000`](http://54.163.215.33:8000) | 8000  | Ambiente principal (branch `main`)    |
| **Staging**  | [`http://54.163.215.33:8001`](http://54.163.215.33:8001) | 8001  | Ambiente de testes (branch `develop`) |

- Api key para testes na porta 8000 : Api-Key 1234567890abcdef
- Api key para testes na porta 8001 : Api-Key 1234567890teste



## ğŸ”’ SeguranÃ§a e GitHub Secrets

A seguranÃ§a das credenciais Ã© fundamental e Ã© tratada da seguinte forma:

1.  **Localmente:** O arquivo `.env` NUNCA deve ser comitado no repositÃ³rio. Ele estÃ¡ incluÃ­do no `.gitignore` por padrÃ£o.
2.  **CI/CD (GitHub Actions):** As credenciais para o deploy nÃ£o sÃ£o expostas no cÃ³digo. Elas sÃ£o armazenadas de forma segura na seÃ§Ã£o **Settings > Secrets and variables > Actions** do repositÃ³rio no GitHub.

Os secrets necessÃ¡rios para o pipeline de CI/CD sÃ£o:

-   `DOCKER_USERNAME`: Seu nome de usuÃ¡rio do Docker Hub.
-   `DOCKER_PASSWORD`: Sua senha ou (recomendado) um Access Token do Docker Hub.
-   `EC2_HOST`: O endereÃ§o IP ou DNS da sua instÃ¢ncia EC2.
-   `EC2_USERNAME`: O nome de usuÃ¡rio para se conectar via SSH (ex: `ubuntu`).
-   `EC2_SSH_KEY`: A chave SSH privada (formato PEM) usada para autenticar na instÃ¢ncia EC2.


---

## ğŸ’¡ ExplicaÃ§Ãµes sobre DecisÃµes TÃ©cnicas

Diversas escolhas de arquitetura e tecnologia foram feitas para garantir robustez, simplicidade de deploy e boas prÃ¡ticas.

### 1. Poetry para Gerenciamento de DependÃªncias

* **Poetry** foi adotado por seu robusto gerenciamento de dependÃªncias atravÃ©s do arquivo `pyproject.toml`.
* O principal benefÃ­cio Ã© o arquivo `poetry.lock`, que garante um **resolvedor de dependÃªncias determinÃ­stico**. Isso significa que os ambientes de desenvolvimento, CI e produÃ§Ã£o usarÃ£o *exatamente* as mesmas versÃµes de todas as bibliotecas, garantindo compilaÃ§Ãµes 100% reprodutÃ­veis e evitando conflitos.

### 2. Stack Docker (Docker, Docker Compose e Docker Hub)

* **Docker:** Foi utilizado para containerizar a aplicaÃ§Ã£o. O `Dockerfile` define um ambiente exato e imutÃ¡vel (Python, bibliotecas do sistema), garantindo **paridade de ambiente** entre desenvolvimento e produÃ§Ã£o.
* **Docker Compose:** Foi usado para orquestrar os serviÃ§os. O `docker-compose.yaml` define e conecta os serviÃ§os necessÃ¡rios (`app` para o Django e `db` para o PostgreSQL), simplificando a inicializaÃ§Ã£o de todo o ambiente com um Ãºnico comando.
* **Docker Hub:** Foi escolhido como o **Registro de Imagens** (Image Registry). O pipeline de CI/CD envia a imagem Docker da aplicaÃ§Ã£o para o Docker Hub apÃ³s um build bem-sucedido. O servidor de produÃ§Ã£o (EC2) entÃ£o baixa essa imagem, desacoplando o processo de build do processo de deploy.

### 3. AutenticaÃ§Ã£o por API Key (Customizada)

* Foi implementada uma autenticaÃ§Ã£o simples baseada em uma **API Key estÃ¡tica**, validada por uma permissÃ£o customizada (`api/permissions.py`). O `Header` esperado Ã© `Authorization: ApiKey SUA_CHAVE`.


### 4. Deploy na AWS EC2 via SSH

* O deploy foi direcionado a uma instÃ¢ncia **AWS EC2** (Infraestrutura como ServiÃ§o).
* Esta escolha oferece **controle total sobre o ambiente** de produÃ§Ã£o. O pipeline de CI/CD (GitHub Actions) simplesmente se conecta via **SSH** e executa comandos do `docker-compose` (`pull` e `up`). Isso torna o processo de deploy direto, transparente e fÃ¡cil de depurar, pois depende apenas de Docker e SSH instalados no servidor.

### 5. Script.sh (Container Entrypoint)

* Este script Ã© utilizado como o `CMD` do `Dockerfile` da aplicaÃ§Ã£o.
*  Ele atua como um "script de inicializaÃ§Ã£o" que garante a ordem correta das operaÃ§Ãµes ao iniciar o container, resolvendo um problema clÃ¡ssico de *race condition* em ambientes orquestrados como o Docker Compose.

    1.  **Espera pelo Banco:** O comando `until nc -z $DB_HOST $DB_PORT` forÃ§a o script a pausar e testar a conexÃ£o com o banco de dados em *loop*. A aplicaÃ§Ã£o sÃ³ prossegue quando o container do PostgreSQL estÃ¡ totalmente pronto para aceitar conexÃµes.
    2.  **MigraÃ§Ãµes AutomÃ¡ticas:** Antes de iniciar o servidor, o script aplica automaticamente quaisquer migraÃ§Ãµes pendentes (`makemigrations` e `migrate`). Isso garante que o *schema* do banco de dados esteja sempre sincronizado com o cÃ³digo da aplicaÃ§Ã£o, automatizando o setup.
    3.  **ExecuÃ§Ã£o do Servidor:** Somente apÃ³s o banco estar pronto e as migraÃ§Ãµes aplicadas, o servidor Django Ã© iniciado. Ele Ã© executado em `0.0.0.0:8000` para ser acessÃ­vel de fora do container, permitindo que o Docker exponha a porta `8000` para a mÃ¡quina host.


## ğŸ“ DecisÃµes, Dificuldades e Melhorias

### DecisÃµes de ImplementaÃ§Ã£o

A decisÃ£o de arquitetura mais importante foi a estratÃ©gia de deploy e rollback.

* **Versionamento de Imagens no Docker Hub:** Em vez de usar apenas a tag `:latest` (que Ã© sobrescrita a cada deploy), o pipeline de CI/CD foi configurado para criar uma tag Ãºnica para cada commit (ex: `...:a1b2c3d`).
* **Por quÃª?** Isso cria um "histÃ³rico" permanente de todas as versÃµes da aplicaÃ§Ã£o no Docker Hub. Se um novo deploy falhar, a imagem da versÃ£o anterior ainda existe e pode ser acessada, o que torna o **rollback manual** (descrito no fluxo de deploy) um processo simples e seguro.

* **SeparaÃ§Ã£o de Ambientes (Staging/ProduÃ§Ã£o):** Decidi criar dois ambientes isolados (`~/app_prod` e `~/app_staging`) no mesmo servidor, cada um com seu prÃ³prio `docker-compose.yaml` e banco de dados.
* **Por quÃª?** Isso me permitiu ter um ambiente seguro de testes (`staging`) para validar as mudanÃ§as da branch `develop` antes de enviÃ¡-las para os usuÃ¡rios reais na branch `main`.



### Dificuldades Encontradas

Como desenvolvedor iniciante, o maior desafio foi integrar mÃºltiplas tecnologias novas de uma sÃ³ vez.

* **Ferramentas atÃ© entÃ£o desconhecidas:** Tive que aprender na prÃ¡tica a usar **Docker** e **Docker Compose** para criar ambientes de desenvolvimento e produÃ§Ã£o isolados. AlÃ©m disso, aprender a configurar e interagir com uma instÃ¢ncia **AWS EC2** (lidando com chaves SSH, Security Groups e gerenciamento de memÃ³ria) foi um grande passo alÃ©m do desenvolvimento local.

* **Fluxo CI/CD:** A parte mais complexa nÃ£o foi apenas escrever o arquivo `.yml` do GitHub Actions, mas **depurÃ¡-lo**. Entender *por que* o pipeline ficava "verde" (sucesso) no GitHub, mas a aplicaÃ§Ã£o nÃ£o subia na EC2, foi o maior desafio. Isso me forÃ§ou a aprender a ler os logs do Docker remotamente (descobrindo o erro `Exited (137)` de falta de memÃ³ria) e a entender como os comandos de deploy (como o `sed`) poderiam falhar silenciosamente.

* **CriaÃ§Ã£o de Testes:** AlÃ©m de aprender a escrever os testes unitÃ¡rios e de integraÃ§Ã£o (`manage.py test api`), o desafio foi fazer o pipeline **usar** esses testes de forma eficaz. Configurar o workflow de CI para iniciar um banco de dados PostgreSQL temporÃ¡rio (na seÃ§Ã£o `services:`) apenas para os testes foi um aprendizado crucial para garantir que o cÃ³digo era validado em um ambiente realista antes de qualquer deploy.

Apesar das dificuldades, foi uma experiÃªncia excelente para estudar e aprender como um projeto real funciona do cÃ³digo Ã  produÃ§Ã£o.

### Melhorias Propostas (PrÃ³ximos Passos)

O projeto estÃ¡ funcional, mas para ser considerado pronto para produÃ§Ã£o real, estas seriam as prÃ³ximas melhorias:

* **Automatizar o Rollback:** Atualmente, o rollback Ã© um processo manual (acessar a EC2, editar o `.yaml`, rodar `docker-compose`). Uma melhoria seria criar um *outro* pipeline no GitHub Actions (talvez usando `workflow_dispatch` com um input) que receba a tag de uma imagem estÃ¡vel e execute o rollback automaticamente.
* **Gunicorn + Nginx:** O log da aplicaÃ§Ã£o avisa que o `runserver` nÃ£o Ã© para produÃ§Ã£o. O prÃ³ximo passo seria:
    1.  Substituir `python manage.py runserver` por `gunicorn` (um servidor de aplicaÃ§Ã£o WSGI robusto).
    2.  Adicionar um **Nginx** como proxy reverso para gerenciar o trÃ¡fego, servir os arquivos estÃ¡ticos (corrigindo o CSS da interface do DRF) e habilitar HTTPS.




## ğŸ‘¨â€ğŸ’» Autor

Projeto desenvolvido por **Carlos Eduardo Medeiros da Silva** como parte do Desafio TÃ©cnico Lacrei SaÃºde.

-   **GitHub:** [Carlos98770](https://github.com/Carlos98770)
-   **RepositÃ³rio do Projeto:** [github.com/Carlos98770/desafio-tecnico](https://github.com/Carlos98770/desafio-tecnico)