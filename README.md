# ü©∫ API (Lacrei Sa√∫de)

API REST desenvolvida com **Django REST Framework (DRF)** para o gerenciamento de **profissionais de sa√∫de** e **consultas m√©dicas**.

O projeto √© totalmente containerizado com **Docker**, utiliza **PostgreSQL** como banco de dados e implementa um pipeline de **CI/CD** com **GitHub Actions** para build, teste, push para o **Docker Hub** e deploy automatizado em uma inst√¢ncia **AWS EC2**.

---

## Tabela de Conte√∫do

- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Arquitetura e Estrutura do Projeto](#-arquitetura-e-estrutura-do-projeto)
- [Configura√ß√£o do Ambiente Local](#-configura√ß√£o-do-ambiente-local)
- [Documenta√ß√£o da API (Endpoints)](#-documenta√ß√£o-da-api-endpoints)
- [Autentica√ß√£o e Seguran√ßa](#-autentica√ß√£o-e-seguran√ßa)
- [Logs e Erros](#logs-e-erros)
- [Testes Automatizados](#-testes-automatizados)
- [Pipeline de CI/CD](#-pipeline-de-cicd)
- [Deploy na AWS EC2](#-deploy-na-aws-ec2)
- [Seguran√ßa e GitHub Secrets](#-seguran√ßa-e-github-secrets)
- [Explica√ß√µes sobre Decis√µes T√©cnicas](#-explica√ß√µes-sobre-decis√µes-t√©cnicas)
- [Decis√µes, Dificuldades e Melhorias](#-decis√µes-dificuldades-e-melhorias)
- [Autor](#-autor)

---

## üöÄ Tecnologias Utilizadas

Este projeto utiliza um stack moderno focado em escalabilidade:

-   üêç **Python** & **Poetry**: Gerenciamento de depend√™ncias e ambiente virtual.
-   üíª **Django** & **Django REST Framework**: Backend robusto para cria√ß√£o da API.
-   üóÉÔ∏è **PostgreSQL**: Banco de dados relacional.
-   üê≥ **Docker** & **Docker Compose**: Containeriza√ß√£o e orquestra√ß√£o dos servi√ßos.
-   ‚òÅÔ∏è **AWS EC2**: Servidor em nuvem para hospedagem da aplica√ß√£o.
-   üì¶ **Docker Hub**: Registro para armazenamento das imagens Docker.
-   üîÑ **GitHub Actions**: Automa√ß√£o do pipeline de Integra√ß√£o Cont√≠nua e Deploy Cont√≠nuo (CI/CD).

---

## üìÅ Arquitetura e Estrutura do Projeto

A estrutura do projeto segue o padr√£o Django, separando a l√≥gica da API em um app dedicado (`api`) e as configura√ß√µes do projeto em `lacrei_saude`.

```bash
    .
‚îú‚îÄ‚îÄ api
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ admin.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ apps.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ migrations/
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ permissions.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ serializers.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ tests
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ urls.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ views.py
‚îú‚îÄ‚îÄ docker-compose.yaml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ lacrei_saude
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ asgi.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ settings.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ urls.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ wsgi.py
‚îú‚îÄ‚îÄ manage.py
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ script.sh
‚îî‚îÄ‚îÄ .github/workflows
    ‚îú‚îÄ‚îÄ ci_cd.yaml



```

---

##  Configura√ß√£o do Ambiente Local

Para executar este projeto localmente usando Docker, siga os passos abaixo.

### Pr√©-requisitos

-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/get-started)
-   [Docker Compose](https://docs.docker.com/compose/install/)

### Instru√ß√µes para rodar o projeto

1.  **Clone o reposit√≥rio:**
    ```sh
    git clone [https://github.com/Carlos98770/desafio-tecnico](https://github.com/Carlos98770/desafio-tecnico)
    cd desafio-tecnico
    ```

2.  **Crie o arquivo de ambiente:**
    Crie o arquivo`.env` no diretorio do projeto:

    ```bash
    API_KEY=sua_api_key
    DB_HOST=db  #manter "db"
    DB_NAME=seu_nome_banco
    DB_USER=seu-user
    DB_PASSWORD=sua-senha
    DB_PORT=5432
    DEBUG=True
    ALLOWED_HOSTS=localhost
        
    DATABASE_URL=postgres://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}

    ```

3.  **Ajuste o `docker-compose.yaml` para Desenvolvimento:**
    O arquivo `docker-compose.yaml` vem configurado por padr√£o para **produ√ß√£o** (usando a imagem pronta `carlos98770/django_rest-api:latest`). Para rodar em modo de **desenvolvimento local**, voc√™ precisa alter√°-lo:

    * **Comente** as linhas da se√ß√£o `#producao`.
    * **Descomente** as linhas da se√ß√£o `#desenvolvimento`.

    **Antes (Padr√£o - Produ√ß√£o):**
    ```yaml
      app:
        #producao
        image: carlos98770/django_rest-api:latest
        container_name: app_app_1
        env_file:
          - .env
        depends_on:
          - db
        ports:
          - "8000:8000"  

        #desenvolvimento
        # build: .
        # volumes:
        #   - .:/app
        # env_file:
        #   - .env
        # depends_on:
        #   - db
        # ports:
        #   - "8000:8000"
    ```

    **Depois (Modo Desenvolvimento):**
    ```yaml
      app:
        #producao
        # image: carlos98770/django_rest-api:latest
        # container_name: app_app_1
        # env_file:
        #   - .env
        # depends_on:
        #   - db
        # ports:
        #   - "8000:8000"  

        #desenvolvimento
        build: .
        volumes:
          - .:/app
        env_file:
          - .env
        depends_on:
          - db
        ports:
          - "8000:8000"
    ```
    * **Por qu√™?** O modo desenvolvimento usa `build: .` (constr√≥i a imagem localmente) e `volumes: - .:/app` (espelha seu c√≥digo local dentro do container). Isso permite que o servidor Django reinicie automaticamente (hot-reload) sempre que voc√™ salvar uma altera√ß√£o no c√≥digo.

4.  **Construa e suba os containers:**
    Este comando ir√° construir a imagem da aplica√ß√£o (se n√£o existir) e iniciar os servi√ßos `app` (Django) e `db` (PostgreSQL) em background.
    ```sh
    sudo docker-compose up -d --build
    ```
     -  **Nota:** O container da API (`app`) executa o `script.sh` na inicializa√ß√£o, que j√° **aguarda o PostgreSQL**, **aplica as migra√ß√µes** automaticamente (`python manage.py migrate`) e **inicia o servidor Django**. Caso o `script.sh` tenha sido editado no Windows, certifique-se de que ele esteja utilizando o formato de quebra de linha **LF (Unix)** para evitar erros de execu√ß√£o no ambiente Linux do container.

5.  **(Opcional) Crie um superusu√°rio:**
    Para acessar a interface de admin do Django (`/admin`).
    ```sh
    docker-compose exec app poetry run python manage.py createsuperuser
    ```

üéâ **Pronto!** A API estar√° acess√≠vel em `http://localhost:8000/api/`.

---

## üó∫Ô∏è Documenta√ß√£o da API (Endpoints)

A URL base para todos os endpoints √© `/api/`. 

| M√©todo HTTP | Endpoint | Descri√ß√£o |
| :--- | :--- | :--- |
| `GET` | `/profissionais/` | Lista todos os profissionais de sa√∫de. |
| `POST` | `/profissionais/` | Cria um novo profissional. |
| `GET` | `/profissionais/<id>/` | Obt√©m detalhes de um profissional espec√≠fico. |
| `PUT` | `/profissionais/<id>/` | Atualiza (completo) um profissional espec√≠fico. |
| `PATCH` | `/profissionais/<id>/` | Atualiza (parcial) um profissional espec√≠fico. |
| `DELETE` | `/profissionais/<id>/` | Remove um profissional. |
| `GET` | `/consultas/` | Lista todas as consultas agendadas. |
| `POST` | `/consultas/` | Agenda uma nova consulta. |
| `GET` | `/consultas/<id>/` | Obt√©m detalhes de uma consulta espec√≠fica. |
| `DELETE` | `/consultas/<id>/` | Cancela (remove) uma consulta. |
| `GET` | `/consultas/profissional/<id>/` | Lista todas as consultas de um profissional espec√≠fico. |

---


## üîë Autentica√ß√£o e seguran√ßa


A API implementa duas camadas principais de seguran√ßa: autentica√ß√£o por API Key e controle de acesso de origem (CORS).

1 -  **API Key**. Esta implementa√ß√£o utiliza uma classe de permiss√£o customizada (`api/permissions.py`) que verifica a chave em cada requisi√ß√£o.

Para se autenticar, inclua a chave no cabe√ßalho `Authorization` da sua requisi√ß√£o, prefixada com `ApiKey`.

**Exemplo de Header:**

```sh
    Authorization: Api-Key SUA_CHAVE_SECRETA_DEFINIDA_NO_ENV
```

A chave utilizada pelo servidor √© definida na vari√°vel de ambiente `API_KEY`.

2 - **CORS**:
- O projeto utiliza django-cors-headers para restringir quais dom√≠nios podem fazer requisi√ß√µes √† API a partir de um navegador.

- Em Produ√ß√£o (DEBUG=False): Apenas as origens listadas na vari√°vel de ambiente CORS_ORIGINS s√£o permitidas. Ex: CORS_ORIGINS=https://frontend.com.

- Em Desenvolvimento (DEBUG=True): Para facilitar os testes locais, origens comuns como http://localhost:5173 e http://localhost:8000 s√£o permitidas automaticamente

---

## üßæ Logs e Erros

A aplica√ß√£o Django REST Framework est√° configurada para registrar automaticamente **logs de acesso** e **logs de erro**, definidos no arquivo `settings.py` atrav√©s do dicion√°rio `LOGGING`.

Esses logs s√£o armazenados dentro da pasta `logs/` no container Docker, e podem ser acessados facilmente seguindo os passos abaixo.

---

### üîç Visualizando logs dentro do container

1Ô∏è‚É£ **Liste os containers em execu√ß√£o:**
```bash
docker ps
```
2Ô∏è‚É£ Entre no container:
```
docker exec it nome_container bash
```
3Ô∏è‚É£ Acesse a pasta de logs:
- Logs de acesso (requisi√ß√µes HTTP):
```bash
tail -f access.log
```
- Logs de erros (exce√ß√µes, falhas, etc):
```bash
tail -f errors.log
```


## üõ°Ô∏è Valida√ß√£o e Sanitiza√ß√£o de Dados

Este projeto implementa rotinas robustas de sanitiza√ß√£o e valida√ß√£o nos serializers do DRF (serializers.py) para garantir a integridade e a consist√™ncia dos dados recebidos pela API.

1. Sanitiza√ß√£o (Limpeza de Dados): Os dados de entrada s√£o "limpos" antes de serem validados:

- Remo√ß√£o de Espa√ßos: Campos de texto (como social_name, adress) utilizam .strip() para remover espa√ßos em branco no in√≠cio e no fim.

- Normaliza√ß√£o de Telefone: O phone_number passa por um re.sub() para remover todos os caracteres n√£o num√©ricos (como (, ), -, ), armazenando apenas os d√≠gitos.

2. Valida√ß√µes (Regras de Neg√≥cio)

- Ap√≥s a limpeza, os dados s√£o validados para garantir que atendem √†s regras da aplica√ß√£o:

- Campos Obrigat√≥rios: Verifica-se se campos essenciais (como social_name, adress, professional_register) n√£o est√£o vazios ap√≥s a sanitiza√ß√£o.

- Formato de Registro: O professional_register s√≥ aceita caracteres alfanum√©ricos e h√≠fen.

- Formato de Telefone: phone_number deve conter um n√∫mero m√≠nimo de d√≠gitos (10) ap√≥s a limpeza.

- Datas de Consultas: O campo data em ConsultasSerializer n√£o pode aceitar datas no passado.

- Regras de Objeto: O m√©todo validate() do ConsultasSerializer verifica regras cruzadas, como impedir o agendamento com profissionais considerados inativos.


## üß™ Testes Automatizados

O projeto possui uma su√≠te de testes (localizada em `api/tests/`) que valida:
-   A l√≥gica dos **Models** (Profissional e Consulta).
-   As opera√ß√µes **CRUD** via API.
-   O funcionamento correto dos **Endpoints**, incluindo c√≥digos de status e valida√ß√µes de dados.

Para executar os testes, utilize o seguinte comando (com os containers rodando):

```sh
docker-compose exec app poetry run python manage.py test api
```

---

---

## üîÑ Pipeline de CI/CD

Este projeto utiliza **GitHub Actions** para automa√ß√£o de Integra√ß√£o Cont√≠nua (CI) e Deploy Cont√≠nuo (CD). O fluxo de trabalho est√° definido no arquivo `.github/workflows/ci_cd.yaml`.

O pipeline √© acionado automaticamente a cada `push` ou `pull request` para a branch `main` e `develop`.

### 1. Integra√ß√£o Cont√≠nua (CI)

A etapa de CI √© executada em **todas as atualiza√ß√µes** (`push` ou `pull request`) e garante a qualidade e integridade do c√≥digo.

1.  **Setup do Ambiente:** O job configura o Python 3.13 e instala o Poetry.
2.  **Banco de Testes:** Um container de servi√ßo com **PostgreSQL 15** √© iniciado para ser usado durante os testes.
3.  **Instala√ß√£o:** As depend√™ncias do projeto s√£o instaladas usando `poetry install`.
4.  **Lint & Formata√ß√£o:** O c√≥digo √© verificado contra padr√µes de formata√ß√£o (`black`) e linting (`flake8`).
5.  **Testes Automatizados:** O pipeline aguarda o banco de dados de teste ficar pronto, aplica as migra√ß√µes (`manage.py migrate`) e executa a su√≠te de testes completa (`manage.py test api`).

### 2. Deploy Cont√≠nuo (CD)

A etapa de CD s√≥ √© executada se a etapa de CI for bem-sucedida:

1.  **Build da Imagem:** A imagem Docker da aplica√ß√£o √© constru√≠da localmente no runner do GitHub.
2.  **Login no Docker Hub:** O pipeline se autentica no Docker Hub usando as credenciais `DOCKERHUB_USERNAME` e `DOCKERHUB_TOKEN` armazenadas nos secrets.
3.  **Push da Imagem:** A imagem rec√©m-constru√≠da √© enviada para o registro do Docker Hub.
4.  **Deploy na AWS EC2:**
    * O pipeline se conecta √† inst√¢ncia EC2 via SSH (usando `EC2_HOST`, `EC2_USER`, `EC2_KEY`).
    * Um script √© executado remotamente no servidor para:
        * Navegar at√© o diret√≥rio da aplica√ß√£o (`~/app_prod`) ou (`~/app_staging`).
        * Parar os servi√ßos atuais com `docker-compose down`.
        * Baixar a nova imagem que acabamos de enviar para o Docker Hub (`docker pull ${{ secrets.DOCKERHUB_USERNAME }}/django-api:{tag}`).
        * Iniciar os servi√ßos novamente com a imagem atualizada (`docker-compose up -d --build`).

---

## ‚òÅÔ∏è Deploy na AWS EC2

A aplica√ß√£o √© hospedada em uma inst√¢ncia **AWS EC2** (Ubuntu Server), onde coexistem dois ambientes isolados: **Staging** (para testes) e **Produ√ß√£o**.

### Configura√ß√£o do Servidor

Para que o deploy automatizado funcione, o servidor EC2 foi configurado com os seguintes pr√©-requisitos:

1.  **Docker** e **Docker Compose** instalados.
2.  **Portas Liberadas:** As portas necess√°rias est√£o abertas no Security Group da AWS:
    * Porta `8000`: Para a aplica√ß√£o de **Produ√ß√£o**.
    * Porta `8001`: Para a aplica√ß√£o de **Staging**.
    * Porta `5432` (DB Produ√ß√£o) e `5433` (DB Staging).
3.  **Chave SSH:** A chave p√∫blica SSH do reposit√≥rio (`EC2_SSH_KEY`) est√° autorizada no arquivo `~/.ssh/authorized_keys` do usu√°rio de deploy.

### Ambientes (Staging e Produ√ß√£o)

Para garantir o isolamento total, os ambientes s√£o gerenciados em diret√≥rios separados no servidor, cada um contendo seus pr√≥prios arquivos de configura√ß√£o:

* **Produ√ß√£o:**
    * **Local:** `~/app_prod/`
    * **Arquivos:** Cont√©m seu pr√≥prio `docker-compose.yaml` (com `container_name: ..._prod`, porta `8000`) e seu arquivo `.env` (com as credenciais de produ√ß√£o).

* **Staging:**
    * **Local:** `~/app_staging/`
    * **Arquivos:** Cont√©m seu pr√≥prio `docker-compose.yaml` (com `container_name: ..._staging`, porta `8001`) e seu arquivo `.env` (com credenciais de teste/staging).
  
  Exemplo de docker-compose.yaml usado:
  ```sh
    version: "3.9"
    services:
      db:
        image: postgres:15
        container_name: postgres_db_staging
        restart: always
        environment:
          POSTGRES_DB: ${DB_NAME}
          POSTGRES_USER: ${DB_USER}
          POSTGRES_PASSWORD: ${DB_PASSWORD}
        volumes:
          - ./data/db_staging:/var/lib/postgresql/data
        ports:
          - "5433:5432" # Porta diferente para n√£o dar conflito com a produ√ß√£o
      app:
        image: carlos98770/django-api:e927c62
        container_name: app_staging
        restart: always
        env_file: .env
        depends_on:
          - db
        ports:
          - "8001:8000" # Porta diferente
    volumes:
      postgres_data:  
    ```


  

### Processo de Deploy (CI/CD)

O pipeline de CI/CD (definido em `.github/workflows/ci_cd.yml`) agora gerencia os dois ambientes baseado na estrat√©gia de branches:

1.  **Build e Teste:** A cada `push` ou `pull request` em `main` ou `develop`, o pipeline executa os testes, lints e o build da imagem Docker.
2.  **Tagging e Push:** A imagem √© versionada com o hash do commit (ex: `...:a1b2c3d`) e enviada ao Docker Hub.
3.  **Deploy em Staging:**
    * **Gatilho:** Um `push` (ou merge) na branch `develop`.
    * **A√ß√£o:** O pipeline se conecta via SSH, entra no diret√≥rio `~/app_staging`, atualiza o `docker-compose.yaml` para usar a nova tag da imagem, baixa a imagem e reinicia os servi√ßos de *staging*.
4.  **Deploy em Produ√ß√£o:**
    * **Gatilho:** Um `push` (ou merge) na branch `main`.
    * **A√ß√£o:** O pipeline executa o mesmo processo, mas desta vez no diret√≥rio `~/app_prod`, atualizando a aplica√ß√£o de produ√ß√£o.

### Fluxo de Rollback

Gra√ßas ao deploy que utiliza tags de imagem √∫nicas baseadas no commit, um rollback de emerg√™ncia √© direto e seguro:

1.  **Identifique** a tag da imagem da vers√£o est√°vel anterior (ex: `...:z9y8x7w`) nos logs do Docker Hub ou do GitHub Actions.
2.  **Acesse** o servidor EC2 via SSH.
3.  **Navegue** at√© o diret√≥rio do ambiente com falha (`~/app_prod` ou `~/app_staging`).
4.  **Edite** o `docker-compose.yaml` (ex: `nano docker-compose.yaml`).
5.  **Altere** a linha `image:` para apontar para a tag da vers√£o est√°vel anterior.
6.  **Execute** `docker-compose up -d`. O Docker ir√° parar o container com bug e substitu√≠-lo pela vers√£o anterior em segundos.

### üåç Endere√ßos de Acesso

A aplica√ß√£o est√° hospedada em uma inst√¢ncia **AWS EC2 (Ubuntu Server 22.04)** e pode ser acessada nos seguintes endere√ßos p√∫blicos:

| Ambiente     | URL de Acesso                                            | Porta | Descri√ß√£o                             |
| ------------- | -------------------------------------------------------- | ----- | ------------------------------------- |
| **Produ√ß√£o** | [`http://54.163.215.33:8000`](http://54.163.215.33:8000) | 8000  | Ambiente principal (branch `main`)    |
| **Staging**  | [`http://54.163.215.33:8001`](http://54.163.215.33:8001) | 8001  | Ambiente de testes (branch `develop`) |

- Api key para testes na porta 8000 : Api-Key 1234567890abcdef
<<<<<<< HEAD
=======
- Api key para testes na porta 8001 : Api-Key 1234567890teste

>>>>>>> feature/logs


## üîí Seguran√ßa e GitHub Secrets

A seguran√ßa das credenciais √© fundamental e √© tratada da seguinte forma:

1.  **Localmente:** O arquivo `.env` NUNCA deve ser comitado no reposit√≥rio. Ele est√° inclu√≠do no `.gitignore` por padr√£o.
2.  **CI/CD (GitHub Actions):** As credenciais para o deploy n√£o s√£o expostas no c√≥digo. Elas s√£o armazenadas de forma segura na se√ß√£o **Settings > Secrets and variables > Actions** do reposit√≥rio no GitHub.

Os secrets necess√°rios para o pipeline de CI/CD s√£o:

-   `DOCKER_USERNAME`: Seu nome de usu√°rio do Docker Hub.
-   `DOCKER_PASSWORD`: Sua senha ou (recomendado) um Access Token do Docker Hub.
-   `EC2_HOST`: O endere√ßo IP ou DNS da sua inst√¢ncia EC2.
-   `EC2_USERNAME`: O nome de usu√°rio para se conectar via SSH (ex: `ubuntu`).
-   `EC2_SSH_KEY`: A chave SSH privada (formato PEM) usada para autenticar na inst√¢ncia EC2.


---

## üí° Explica√ß√µes sobre Decis√µes T√©cnicas

Diversas escolhas de arquitetura e tecnologia foram feitas para garantir robustez, simplicidade de deploy e boas pr√°ticas.

### 1. Poetry para Gerenciamento de Depend√™ncias

* **Poetry** foi adotado por seu robusto gerenciamento de depend√™ncias atrav√©s do arquivo `pyproject.toml`.
* O principal benef√≠cio √© o arquivo `poetry.lock`, que garante um **resolvedor de depend√™ncias determin√≠stico**. Isso significa que os ambientes de desenvolvimento, CI e produ√ß√£o usar√£o *exatamente* as mesmas vers√µes de todas as bibliotecas, garantindo compila√ß√µes 100% reprodut√≠veis e evitando conflitos.

### 2. Stack Docker (Docker, Docker Compose e Docker Hub)

* **Docker:** Foi utilizado para containerizar a aplica√ß√£o. O `Dockerfile` define um ambiente exato e imut√°vel (Python, bibliotecas do sistema), garantindo **paridade de ambiente** entre desenvolvimento e produ√ß√£o.
* **Docker Compose:** Foi usado para orquestrar os servi√ßos. O `docker-compose.yaml` define e conecta os servi√ßos necess√°rios (`app` para o Django e `db` para o PostgreSQL), simplificando a inicializa√ß√£o de todo o ambiente com um √∫nico comando.
* **Docker Hub:** Foi escolhido como o **Registro de Imagens** (Image Registry). O pipeline de CI/CD envia a imagem Docker da aplica√ß√£o para o Docker Hub ap√≥s um build bem-sucedido. O servidor de produ√ß√£o (EC2) ent√£o baixa essa imagem, desacoplando o processo de build do processo de deploy.

### 3. Autentica√ß√£o por API Key (Customizada)

* Foi implementada uma autentica√ß√£o simples baseada em uma **API Key est√°tica**, validada por uma permiss√£o customizada (`api/permissions.py`). O `Header` esperado √© `Authorization: ApiKey SUA_CHAVE`.


### 4. Deploy na AWS EC2 via SSH

* O deploy foi direcionado a uma inst√¢ncia **AWS EC2** (Infraestrutura como Servi√ßo).
* Esta escolha oferece **controle total sobre o ambiente** de produ√ß√£o. O pipeline de CI/CD (GitHub Actions) simplesmente se conecta via **SSH** e executa comandos do `docker-compose` (`pull` e `up`). Isso torna o processo de deploy direto, transparente e f√°cil de depurar, pois depende apenas de Docker e SSH instalados no servidor.

### 5. Script.sh (Container Entrypoint)

* Este script √© utilizado como o `CMD` do `Dockerfile` da aplica√ß√£o.
*  Ele atua como um "script de inicializa√ß√£o" que garante a ordem correta das opera√ß√µes ao iniciar o container, resolvendo um problema cl√°ssico de *race condition* em ambientes orquestrados como o Docker Compose.

    1.  **Espera pelo Banco:** O comando `until nc -z $DB_HOST $DB_PORT` for√ßa o script a pausar e testar a conex√£o com o banco de dados em *loop*. A aplica√ß√£o s√≥ prossegue quando o container do PostgreSQL est√° totalmente pronto para aceitar conex√µes.
    2.  **Migra√ß√µes Autom√°ticas:** Antes de iniciar o servidor, o script aplica automaticamente quaisquer migra√ß√µes pendentes (`makemigrations` e `migrate`). Isso garante que o *schema* do banco de dados esteja sempre sincronizado com o c√≥digo da aplica√ß√£o, automatizando o setup.
    3.  **Execu√ß√£o do Servidor:** Somente ap√≥s o banco estar pronto e as migra√ß√µes aplicadas, o servidor Django √© iniciado. Ele √© executado em `0.0.0.0:8000` para ser acess√≠vel de fora do container, permitindo que o Docker exponha a porta `8000` para a m√°quina host.


## üìù Decis√µes, Dificuldades e Melhorias

### Decis√µes de Implementa√ß√£o

A decis√£o de arquitetura mais importante foi a estrat√©gia de deploy e rollback.

* **Versionamento de Imagens no Docker Hub:** Em vez de usar apenas a tag `:latest` (que √© sobrescrita a cada deploy), o pipeline de CI/CD foi configurado para criar uma tag √∫nica para cada commit (ex: `...:a1b2c3d`).
* **Por qu√™?** Isso cria um "hist√≥rico" permanente de todas as vers√µes da aplica√ß√£o no Docker Hub. Se um novo deploy falhar, a imagem da vers√£o anterior ainda existe e pode ser acessada, o que torna o **rollback manual** (descrito no fluxo de deploy) um processo simples e seguro.

* **Separa√ß√£o de Ambientes (Staging/Produ√ß√£o):** Decidi criar dois ambientes isolados (`~/app_prod` e `~/app_staging`) no mesmo servidor, cada um com seu pr√≥prio `docker-compose.yaml` e banco de dados.
* **Por qu√™?** Isso me permitiu ter um ambiente seguro de testes (`staging`) para validar as mudan√ßas da branch `develop` antes de envi√°-las para os usu√°rios reais na branch `main`.



### Dificuldades Encontradas

Como desenvolvedor iniciante, o maior desafio foi integrar m√∫ltiplas tecnologias novas de uma s√≥ vez.

* **Ferramentas at√© ent√£o desconhecidas:** Tive que aprender na pr√°tica a usar **Docker** e **Docker Compose** para criar ambientes de desenvolvimento e produ√ß√£o isolados. Al√©m disso, aprender a configurar e interagir com uma inst√¢ncia **AWS EC2** (lidando com chaves SSH, Security Groups e gerenciamento de mem√≥ria) foi um grande passo al√©m do desenvolvimento local.

* **Fluxo CI/CD:** A parte mais complexa n√£o foi apenas escrever o arquivo `.yml` do GitHub Actions, mas **depur√°-lo**. Entender *por que* o pipeline ficava "verde" (sucesso) no GitHub, mas a aplica√ß√£o n√£o subia na EC2, foi o maior desafio. Isso me for√ßou a aprender a ler os logs do Docker remotamente (descobrindo o erro `Exited (137)` de falta de mem√≥ria) e a entender como os comandos de deploy (como o `sed`) poderiam falhar silenciosamente.

* **Cria√ß√£o de Testes:** Al√©m de aprender a escrever os testes unit√°rios e de integra√ß√£o (`manage.py test api`), o desafio foi fazer o pipeline **usar** esses testes de forma eficaz. Configurar o workflow de CI para iniciar um banco de dados PostgreSQL tempor√°rio (na se√ß√£o `services:`) apenas para os testes foi um aprendizado crucial para garantir que o c√≥digo era validado em um ambiente realista antes de qualquer deploy.

Apesar das dificuldades, foi uma experi√™ncia excelente para estudar e aprender como um projeto real funciona do c√≥digo √† produ√ß√£o.

### Melhorias Propostas (Pr√≥ximos Passos)

O projeto est√° funcional, mas para ser considerado pronto para produ√ß√£o real, estas seriam as pr√≥ximas melhorias:

* **Automatizar o Rollback:** Atualmente, o rollback √© um processo manual (acessar a EC2, editar o `.yaml`, rodar `docker-compose`). Uma melhoria seria criar um *outro* pipeline no GitHub Actions (talvez usando `workflow_dispatch` com um input) que receba a tag de uma imagem est√°vel e execute o rollback automaticamente.
* **Gunicorn + Nginx:** O log da aplica√ß√£o avisa que o `runserver` n√£o √© para produ√ß√£o. O pr√≥ximo passo seria:
    1.  Substituir `python manage.py runserver` por `gunicorn` (um servidor de aplica√ß√£o WSGI robusto).
    2.  Adicionar um **Nginx** como proxy reverso para gerenciar o tr√°fego, servir os arquivos est√°ticos (corrigindo o CSS da interface do DRF) e habilitar HTTPS.
    3. integra√ß√£o com a AssAs para split de pagamento




## üë®‚Äçüíª Autor

Projeto desenvolvido por **Carlos Eduardo Medeiros da Silva** como parte do Desafio T√©cnico Lacrei Sa√∫de.

-   **GitHub:** [Carlos98770](https://github.com/Carlos98770)
-   **Reposit√≥rio do Projeto:** [github.com/Carlos98770/desafio-tecnico](https://github.com/Carlos98770/desafio-tecnico)