# ğŸ©º API (Lacrei SaÃºde)

API REST desenvolvida com **Django REST Framework (DRF)** para o gerenciamento de **profissionais de saÃºde** e **consultas mÃ©dicas**.

O projeto Ã© totalmente containerizado com **Docker**, utiliza **PostgreSQL** como banco de dados e implementa um pipeline de **CI/CD** com **GitHub Actions** para build, teste, push para o **Docker Hub** e deploy automatizado em uma instÃ¢ncia **AWS EC2**.

---

## Tabela de ConteÃºdo

- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Arquitetura e Estrutura do Projeto](#-arquitetura-e-estrutura-do-projeto)
- [ConfiguraÃ§Ã£o do Ambiente Local](#-configuraÃ§Ã£o-do-ambiente-local)
- [DocumentaÃ§Ã£o da API (Endpoints)](#-documentaÃ§Ã£o-da-api-endpoints)
- [AutenticaÃ§Ã£o](#-autenticaÃ§Ã£o)
- [Testes Automatizados](#-testes-automatizados)
- [Pipeline de CI/CD](#-pipeline-de-cicd)
- [Deploy na AWS EC2](#-deploy-na-aws-ec2)
- [SeguranÃ§a e GitHub Secrets](#-seguranÃ§a-e-github-secrets)
- [Autor](#-autor)

---

## ğŸš€ Tecnologias Utilizadas

Este projeto utiliza um stack moderno focado em escalabilidade e boas prÃ¡ticas de DevOps:

-   ğŸ **Python** & **Poetry**: Gerenciamento de dependÃªncias e ambiente virtual.
-   ğŸ’» **Django** & **Django REST Framework**: Backend robusto para criaÃ§Ã£o da API.
-   ğŸ—ƒï¸ **PostgreSQL**: Banco de dados relacional.
-   ğŸ³ **Docker** & **Docker Compose**: ContainerizaÃ§Ã£o e orquestraÃ§Ã£o dos serviÃ§os.
-   â˜ï¸ **AWS EC2**: Servidor em nuvem para hospedagem da aplicaÃ§Ã£o.
-   ğŸ“¦ **Docker Hub**: Registro para armazenamento das imagens Docker.
-   ğŸ”„ **GitHub Actions**: AutomaÃ§Ã£o do pipeline de IntegraÃ§Ã£o ContÃ­nua e Deploy ContÃ­nuo (CI/CD).

---

## ğŸ“ Arquitetura e Estrutura do Projeto

A estrutura do projeto segue o padrÃ£o Django, separando a lÃ³gica da API em um app dedicado (`api`) e as configuraÃ§Ãµes do projeto em `lacrei_saude`.

```bash
    .
â”œâ”€â”€ api
â”‚Â Â  â”œâ”€â”€ admin.py
â”‚Â Â  â”œâ”€â”€ apps.py
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ migrations/
â”‚Â Â  â”œâ”€â”€ models.py
â”‚Â Â  â”œâ”€â”€ permissions.py
â”‚Â Â  â”œâ”€â”€ serializers.py
â”‚Â Â  â”œâ”€â”€ tests
â”‚Â Â  â”œâ”€â”€ urls.py
â”‚Â Â  â””â”€â”€ views.py
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ lacrei_saude
â”‚Â Â  â”œâ”€â”€ asgi.py
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ settings.py
â”‚Â Â  â”œâ”€â”€ urls.py
â”‚Â Â  â””â”€â”€ wsgi.py
â”œâ”€â”€ manage.py
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ script.sh
â””â”€â”€ .github/workflows
    â”œâ”€â”€ ci_cd.yaml



```

---

##  ConfiguraÃ§Ã£o do Ambiente Local

Para executar este projeto localmente usando Docker, siga os passos abaixo.

### PrÃ©-requisitos

-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/get-started)
-   [Docker Compose](https://docs.docker.com/compose/install/)

### InstruÃ§Ãµes para rodar o projeto

1.  **Clone o repositÃ³rio:**
    ```sh
    git clone [https://github.com/Carlos98770/desafio-tecnico](https://github.com/Carlos98770/desafio-tecnico)
    cd desafio-tecnico
    ```

2.  **Crie o arquivo de ambiente:**
    Crie o arquivo`.env` no diretorio do projeto:

    ```bash
    API_KEY=sua_api_key
    DB_HOST=db  #manter "db"
    DB_NAME=seu_nome_banco
    DB_USER=seu-user
    DB_PASSWORD=sua-senha
    DB_PORT=5432
    DEBUG=True
    ALLOWED_HOSTS=localhost
        
    DATABASE_URL=postgres://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}

    ```

3.  **Ajuste o `docker-compose.yaml` para Desenvolvimento:**
    O arquivo `docker-compose.yaml` vem configurado por padrÃ£o para **produÃ§Ã£o** (usando a imagem pronta `carlos98770/django_rest-api:latest`). Para rodar em modo de **desenvolvimento local**, vocÃª precisa alterÃ¡-lo:

    * **Comente** as linhas da seÃ§Ã£o `#producao`.
    * **Descomente** as linhas da seÃ§Ã£o `#desenvolvimento`.

    **Antes (PadrÃ£o - ProduÃ§Ã£o):**
    ```yaml
      app:
        #producao
        image: carlos98770/django_rest-api:latest
        container_name: app_app_1
        env_file:
          - .env
        depends_on:
          - db
        ports:
          - "8000:8000"  

        #desenvolvimento
        # build: .
        # volumes:
        #   - .:/app
        # env_file:
        #   - .env
        # depends_on:
        #   - db
        # ports:
        #   - "8000:8000"
    ```

    **Depois (Modo Desenvolvimento):**
    ```yaml
      app:
        #producao
        # image: carlos98770/django_rest-api:latest
        # container_name: app_app_1
        # env_file:
        #   - .env
        # depends_on:
        #   - db
        # ports:
        #   - "8000:8000"  

        #desenvolvimento
        build: .
        volumes:
          - .:/app
        env_file:
          - .env
        depends_on:
          - db
        ports:
          - "8000:8000"
    ```
    * **Por quÃª?** O modo desenvolvimento usa `build: .` (constrÃ³i a imagem localmente) e `volumes: - .:/app` (espelha seu cÃ³digo local dentro do container). Isso permite que o servidor Django reinicie automaticamente (hot-reload) sempre que vocÃª salvar uma alteraÃ§Ã£o no cÃ³digo.

4.  **Construa e suba os containers:**
    Este comando irÃ¡ construir a imagem da aplicaÃ§Ã£o (se nÃ£o existir) e iniciar os serviÃ§os `app` (Django) e `db` (PostgreSQL) em background.
    ```sh
    sudo docker-compose up -d --build
    ```
     -  **Nota:** O container da API (`app`) executa o `script.sh` na inicializaÃ§Ã£o, que jÃ¡ **aguarda o PostgreSQL**, **aplica as migraÃ§Ãµes** automaticamente (`python manage.py migrate`) e **inicia o servidor Django**. Caso o `script.sh` tenha sido editado no Windows, certifique-se de que ele esteja utilizando o formato de quebra de linha **LF (Unix)** para evitar erros de execuÃ§Ã£o no ambiente Linux do container.

5.  **(Opcional) Crie um superusuÃ¡rio:**
    Para acessar a interface de admin do Django (`/admin`).
    ```sh
    docker-compose exec app poetry run python manage.py createsuperuser
    ```

ğŸ‰ **Pronto!** A API estarÃ¡ acessÃ­vel em `http://localhost:8000/api/`.

---

## ğŸ—ºï¸ DocumentaÃ§Ã£o da API (Endpoints)

A URL base para todos os endpoints Ã© `/api/`.

| MÃ©todo HTTP | Endpoint | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `GET` | `/profissionais/` | Lista todos os profissionais de saÃºde. |
| `POST` | `/profissionais/` | Cria um novo profissional. |
| `GET` | `/profissionais/<id>/` | ObtÃ©m detalhes de um profissional especÃ­fico. |
| `PUT` | `/profissionais/<id>/` | Atualiza (completo) um profissional especÃ­fico. |
| `PATCH` | `/profissionais/<id>/` | Atualiza (parcial) um profissional especÃ­fico. |
| `DELETE` | `/profissionais/<id>/` | Remove um profissional. |
| `GET` | `/consultations/` | Lista todas as consultas agendadas. |
| `POST` | `/consultations/` | Agenda uma nova consulta. |
| `GET` | `/consultations/<id>/` | ObtÃ©m detalhes de uma consulta especÃ­fica. |
| `DELETE` | `/consultations/<id>/` | Cancela (remove) uma consulta. |
| `GET` | `/consultations/profissional/<id>/` | Lista todas as consultas de um profissional especÃ­fico. |

---


## ğŸ”‘ AutenticaÃ§Ã£o

O acesso Ã  API Ã© protegido por **API Key**. Esta implementaÃ§Ã£o utiliza uma classe de permissÃ£o customizada (`api/permissions.py`) que verifica a chave em cada requisiÃ§Ã£o.

Para se autenticar, inclua a chave no cabeÃ§alho `Authorization` da sua requisiÃ§Ã£o, prefixada com `ApiKey`.

**Exemplo de Header:**

```sh
    Authorization: ApiKey SUA_CHAVE_SECRETA_DEFINIDA_NO_ENV
```

A chave utilizada pelo servidor Ã© definida na variÃ¡vel de ambiente `API_KEY`.

---


## ğŸ§ª Testes Automatizados

O projeto possui uma suÃ­te de testes (localizada em `api/tests/`) que valida:
-   A lÃ³gica dos **Models** (Profissional e Consulta).
-   As operaÃ§Ãµes **CRUD** via API.
-   O funcionamento correto dos **Endpoints**, incluindo cÃ³digos de status e validaÃ§Ãµes de dados.

Para executar os testes, utilize o seguinte comando (com os containers rodando):

```sh
docker-compose exec app poetry run python manage.py test api
```

---

---

## ğŸ”„ Pipeline de CI/CD

Este projeto utiliza **GitHub Actions** para automaÃ§Ã£o de IntegraÃ§Ã£o ContÃ­nua (CI) e Deploy ContÃ­nuo (CD). O fluxo de trabalho estÃ¡ definido no arquivo `.github/workflows/ci_cd.yaml`.

O pipeline Ã© acionado automaticamente a cada `push` ou `pull request` para a branch `main`.

### 1. IntegraÃ§Ã£o ContÃ­nua (CI)

A etapa de CI Ã© executada em **todas as atualizaÃ§Ãµes** (`push` ou `pull request`) e garante a qualidade e integridade do cÃ³digo.

1.  **Setup do Ambiente:** O job configura o Python 3.13 e instala o Poetry.
2.  **Banco de Testes:** Um container de serviÃ§o com **PostgreSQL 15** Ã© iniciado para ser usado durante os testes.
3.  **InstalaÃ§Ã£o:** As dependÃªncias do projeto sÃ£o instaladas usando `poetry install`.
4.  **Lint & FormataÃ§Ã£o:** O cÃ³digo Ã© verificado contra padrÃµes de formataÃ§Ã£o (`black`) e linting (`flake8`).
5.  **Testes Automatizados:** O pipeline aguarda o banco de dados de teste ficar pronto, aplica as migraÃ§Ãµes (`manage.py migrate`) e executa a suÃ­te de testes completa (`manage.py test api`).

### 2. Deploy ContÃ­nuo (CD)

A etapa de CD sÃ³ Ã© executada se a etapa de CI for bem-sucedida:

1.  **Build da Imagem:** A imagem Docker da aplicaÃ§Ã£o Ã© construÃ­da localmente no runner do GitHub.
2.  **Login no Docker Hub:** O pipeline se autentica no Docker Hub usando as credenciais `DOCKERHUB_USERNAME` e `DOCKERHUB_TOKEN` armazenadas nos secrets.
3.  **Push da Imagem:** A imagem recÃ©m-construÃ­da Ã© enviada para o registro do Docker Hub com a tag `latest` (ex: `carlos98770/django-api:latest`).
4.  **Deploy na AWS EC2:**
    * O pipeline se conecta Ã  instÃ¢ncia EC2 via SSH (usando `EC2_HOST`, `EC2_USER`, `EC2_KEY`).
    * Um script Ã© executado remotamente no servidor para:
        * Navegar atÃ© o diretÃ³rio da aplicaÃ§Ã£o (`~/app`).
        * Parar os serviÃ§os atuais com `docker-compose down`.
        * Baixar a nova imagem que acabamos de enviar para o Docker Hub (`docker pull ${{ secrets.DOCKERHUB_USERNAME }}/django-api:latest`).
        * Iniciar os serviÃ§os novamente com a imagem atualizada (`docker-compose up -d --build`).

---

## â˜ï¸ Deploy na AWS EC2

A aplicaÃ§Ã£o Ã© hospedada em uma instÃ¢ncia **AWS EC2** (Ubuntu Server).

### ConfiguraÃ§Ã£o do Servidor

Para que o deploy automatizado funcione, o servidor EC2 deve ter:

1.  **Docker** instalado.
2.  **Docker Compose** instalado.
3.  As portas necessÃ¡rias (ex: `8000`) liberadas no Security Group.
4.  A chave pÃºblica SSH correspondente Ã  chave privada (`EC2_SSH_KEY`) adicionada ao arquivo `~/.ssh/authorized_keys` do usuÃ¡rio de deploy.

### Processo de Deploy

O pipeline de CI/CD Ã© responsÃ¡vel por todo o processo. Ao receber um `push | pull request` na `main`, o GitHub Actions constrÃ³i a nova imagem e "avisa" o servidor EC2 (via SSH) para baixar e executar essa nova versÃ£o, garantindo um deploy "zero-downtime" (ou com o mÃ­nimo possÃ­vel) gerenciado pelo Docker Compose.

---

## ğŸ”’ SeguranÃ§a e GitHub Secrets

A seguranÃ§a das credenciais Ã© fundamental e Ã© tratada da seguinte forma:

1.  **Localmente:** O arquivo `.env` NUNCA deve ser comitado no repositÃ³rio. Ele estÃ¡ incluÃ­do no `.gitignore` por padrÃ£o.
2.  **CI/CD (GitHub Actions):** As credenciais para o deploy nÃ£o sÃ£o expostas no cÃ³digo. Elas sÃ£o armazenadas de forma segura na seÃ§Ã£o **Settings > Secrets and variables > Actions** do repositÃ³rio no GitHub.

Os secrets necessÃ¡rios para o pipeline de CI/CD sÃ£o:

-   `DOCKER_USERNAME`: Seu nome de usuÃ¡rio do Docker Hub.
-   `DOCKER_PASSWORD`: Sua senha ou (recomendado) um Access Token do Docker Hub.
-   `EC2_HOST`: O endereÃ§o IP ou DNS da sua instÃ¢ncia EC2.
-   `EC2_USERNAME`: O nome de usuÃ¡rio para se conectar via SSH (ex: `ubuntu`).
-   `EC2_SSH_KEY`: A chave SSH privada (formato PEM) usada para autenticar na instÃ¢ncia EC2.


---

## ğŸ’¡ ExplicaÃ§Ãµes sobre DecisÃµes TÃ©cnicas

Diversas escolhas de arquitetura e tecnologia foram feitas para garantir robustez, simplicidade de deploy e boas prÃ¡ticas.

### 1. Poetry para Gerenciamento de DependÃªncias

* **Poetry** foi adotado por seu robusto gerenciamento de dependÃªncias atravÃ©s do arquivo `pyproject.toml`.
* O principal benefÃ­cio Ã© o arquivo `poetry.lock`, que garante um **resolvedor de dependÃªncias determinÃ­stico**. Isso significa que os ambientes de desenvolvimento, CI e produÃ§Ã£o usarÃ£o *exatamente* as mesmas versÃµes de todas as bibliotecas, garantindo compilaÃ§Ãµes 100% reprodutÃ­veis e evitando conflitos.

### 2. Stack Docker (Docker, Docker Compose e Docker Hub)

* **Docker:** Foi utilizado para containerizar a aplicaÃ§Ã£o. O `Dockerfile` define um ambiente exato e imutÃ¡vel (Python, bibliotecas do sistema), garantindo **paridade de ambiente** entre desenvolvimento e produÃ§Ã£o.
* **Docker Compose:** Foi usado para orquestrar os serviÃ§os. O `docker-compose.yaml` define e conecta os serviÃ§os necessÃ¡rios (`app` para o Django e `db` para o PostgreSQL), simplificando a inicializaÃ§Ã£o de todo o ambiente com um Ãºnico comando.
* **Docker Hub:** Foi escolhido como o **Registro de Imagens** (Image Registry). O pipeline de CI/CD envia a imagem Docker da aplicaÃ§Ã£o para o Docker Hub apÃ³s um build bem-sucedido. O servidor de produÃ§Ã£o (EC2) entÃ£o baixa essa imagem, desacoplando o processo de build do processo de deploy.

### 3. AutenticaÃ§Ã£o por API Key (Customizada)

* Foi implementada uma autenticaÃ§Ã£o simples baseada em uma **API Key estÃ¡tica**, validada por uma permissÃ£o customizada (`api/permissions.py`). O `Header` esperado Ã© `Authorization: ApiKey SUA_CHAVE`.
*  Esta Ã© uma abordagem pragmÃ¡tica e segura para proteger endpoints de API (especialmente para comunicaÃ§Ã£o mÃ¡quina-a-mÃ¡quina ou M2M). Ela Ã© *stateless* (nÃ£o exige uma sessÃ£o de banco de dados) e sua implementaÃ§Ã£o Ã© direta e adequada ao escopo do projeto.

### 4. Deploy na AWS EC2 via SSH

* O deploy foi direcionado a uma instÃ¢ncia **AWS EC2** (Infraestrutura como ServiÃ§o).
* Esta escolha oferece **controle total sobre o ambiente** de produÃ§Ã£o. O pipeline de CI/CD (GitHub Actions) simplesmente se conecta via **SSH** e executa comandos do `docker-compose` (`pull` e `up`). Isso torna o processo de deploy direto, transparente e fÃ¡cil de depurar, pois depende apenas de Docker e SSH instalados no servidor.

### 5. Script.sh (Container Entrypoint)

* Este script Ã© utilizado como o `CMD` do `Dockerfile` da aplicaÃ§Ã£o.
*  Ele atua como um "script de inicializaÃ§Ã£o" que garante a ordem correta das operaÃ§Ãµes ao iniciar o container, resolvendo um problema clÃ¡ssico de *race condition* em ambientes orquestrados como o Docker Compose.

    1.  **Espera pelo Banco:** O comando `until nc -z $DB_HOST $DB_PORT` forÃ§a o script a pausar e testar a conexÃ£o com o banco de dados em *loop*. A aplicaÃ§Ã£o sÃ³ prossegue quando o container do PostgreSQL estÃ¡ totalmente pronto para aceitar conexÃµes.
    2.  **MigraÃ§Ãµes AutomÃ¡ticas:** Antes de iniciar o servidor, o script aplica automaticamente quaisquer migraÃ§Ãµes pendentes (`makemigrations` e `migrate`). Isso garante que o *schema* do banco de dados esteja sempre sincronizado com o cÃ³digo da aplicaÃ§Ã£o, automatizando o setup.
    3.  **ExecuÃ§Ã£o do Servidor:** Somente apÃ³s o banco estar pronto e as migraÃ§Ãµes aplicadas, o servidor Django Ã© iniciado. Ele Ã© executado em `0.0.0.0:8000` para ser acessÃ­vel de fora do container, permitindo que o Docker exponha a porta `8000` para a mÃ¡quina host.


## ğŸ“ DecisÃµes de ImplementaÃ§Ã£o e Melhorias Propostas
melhorias: automatizar a questao do docker-compose.yaml producao e densevolvimento




## ğŸ‘¨â€ğŸ’» Autor

Projeto desenvolvido por **Carlos Eduardo Medeiros da Silva** como parte do Desafio TÃ©cnico Lacrei SaÃºde.

-   **GitHub:** [Carlos98770](https://github.com/Carlos98770)
-   **RepositÃ³rio do Projeto:** [github.com/Carlos98770/desafio-tecnico](https://github.com/Carlos98770/desafio-tecnico)